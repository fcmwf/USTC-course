{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "from math import log \n",
    "import math\n",
    "from anytree import Node, RenderTree\n",
    "from anytree.dotexport import RenderTreeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_value(y_col):\n",
    "    counter = Counter(y_col)\n",
    "    # 计算总样本数\n",
    "    total_count = len(y_col)\n",
    "    # 计算概率\n",
    "    probabilities = [count / total_count for count in counter.values()]\n",
    "    # 计算信息熵\n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "# 计算某一个属性的信息增益\n",
    "def get_info_gain_byc(column, df, y_col):\n",
    "    # 计算p(column)\n",
    "    probs = df.groupby(column).size().div(len(df))\n",
    "    v = 0\n",
    "    for index1, v1 in probs.items():\n",
    "        tmp_df = df[df[column] == index1]\n",
    "        tmp_probs = tmp_df.groupby(y_col).size().div(len(tmp_df))\n",
    "        tmp_v = 0\n",
    "        for v2 in tmp_probs:\n",
    "            # 计算H(C|X=xi)\n",
    "            tmp_v += -v2 * log(v2, 2)\n",
    "        # 计算H(y_col|column)\n",
    "        v += v1 * tmp_v\n",
    "    return v\n",
    "\n",
    "# 获取拥有最大信息增益的属性\n",
    "def get_max_info_gain(df, y_col):\n",
    "    d = {}\n",
    "    h = h_value(y_col)\n",
    "    for c in filter(lambda c: c != 'NObeyesdad', df.columns):\n",
    "        # 计算H(y_col) - H(y_col|column)\n",
    "        d[c] = h - get_info_gain_byc(c, df, y_col)\n",
    "\n",
    "    return max(d, key=d.get)\n",
    "\n",
    "\n",
    "def train_decision_tree(node, df, y_col):\n",
    "    c = get_max_info_gain(df, y_col)\n",
    "    for v in pd.unique(df[c]):\n",
    "        gb = df[df[c] == v].groupby(y_col)\n",
    "        curr_node = Node('%s-%s' % (c, v), parent=node)\n",
    "        # 如果属性没有用完\n",
    "        if len(df.columns) > 2:\n",
    "            # 如果分区纯度是100%，则生成类别叶子节点\n",
    "            if len(gb) == 1:  \n",
    "                # print(df[df[c] == v].groupby(c)[y_col].first().iloc[0])\n",
    "                Node(df[df[c] == v].groupby(c)['NObeyesdad'].first().iloc[0], parent=curr_node)\n",
    "                # Node('leaf', parent=curr_node)\n",
    "            else:\n",
    "                # 如果分区不纯则继续递归\n",
    "                # print(df[df[c] == v].drop(c, axis=1))\n",
    "                train_decision_tree(curr_node, df[df[c] == v].drop(c, axis=1), y_col)\n",
    "        # 如果属性用完，则选择数量最多的类别实例作为类别叶子结点\n",
    "        else:\n",
    "            Node(df[df[c] == v].groupby(y_col).size().idxmax(), parent=curr_node)\n",
    "\n",
    "def predict_decision_tree(data : pd, tree : Node ):\n",
    "    predictions = []\n",
    "    with open(\"record.txt\", 'w') as f:\n",
    "        for index , row in data.iterrows():\n",
    "            f.write(str(index) + '\\n')\n",
    "            f.write(row.to_string(header=False) + '\\n')\n",
    "            node = tree   \n",
    "            while len( node.children) != 0:\n",
    "                if( len(node.children) == 1):\n",
    "                    node = node.children[0]\n",
    "                    continue\n",
    "                for child in node.children:\n",
    "                    if isinstance(child.name, str):\n",
    "                        name, _ = child.name.split('-')\n",
    "                        break\n",
    "                        # 其他处理逻辑\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                type  = row[name]\n",
    "                type = int(type)\n",
    "                flag = False\n",
    "                for  child in node.children:\n",
    "                    if isinstance(child.name, str):\n",
    "                        _ , index = child.name.split('-')\n",
    "                        # 其他处理逻辑\n",
    "                    else:\n",
    "                        leaf = child\n",
    "\n",
    "                    index = int(index)\n",
    "                    if index == type:\n",
    "                        node = child\n",
    "                        flag = True\n",
    "                        break\n",
    "                if(flag == False):\n",
    "                    node = leaf\n",
    "            predictions.append(node.name)\n",
    "    return predictions\n",
    "\n",
    "def accuracy( predict , y_test):\n",
    "    # 确保预测值和真实标签的长度相同\n",
    "    if len(predict) != len(y_test):\n",
    "        raise ValueError(\"Length of predict and y_test must be the same.\")\n",
    "\n",
    "    # 计算预测正确的数量\n",
    "    correct_count = sum(1 for pred, true in zip(predict, y_test) if pred == true)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = correct_count / len(y_test)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath:str='./data/ObesityDataSet_raw_and_data_sinthetic.csv'):\n",
    "    df = pd.read_csv(datapath)\n",
    "    \n",
    "    continue_features = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "    discrete_features = ['Gender', 'CALC', 'FAVC', 'SCC', 'SMOKE', 'family_history_with_overweight', 'CAEC', 'MTRANS', 'NObeyesdad']\n",
    "    discrete_features_size = {'Gender':2, 'CALC':4, 'FAVC':2, 'SCC':2, 'SMOKE':2, 'family_history_with_overweight':2, 'CAEC':4, 'MTRANS':5}  \n",
    "\n",
    "    # encode discrete str to number, eg. male&female to 0&1\n",
    "\n",
    "#   # 删除不是离散特征的列\n",
    "#     X, y = df.iloc[:50, :], df.iloc[:50, -1]\n",
    "#     columns_to_drop = [col for col in df.columns if col not in discrete_features]\n",
    "#     X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    median_dict = {}\n",
    "    for feature in continue_features:\n",
    "        # 对特征进行排序\n",
    "        sorted_values = df[feature].sort_values()\n",
    "        \n",
    "        # 计算中位数\n",
    "        median_value = sorted_values.median()\n",
    "        median_dict[feature] = median_value\n",
    "        # 分类：高于或低于中位数\n",
    "        df[feature] = df[feature].apply(lambda x: 1 if x > median_value else 0)\n",
    "\n",
    "\n",
    "    X, y = df.iloc[:, :], df.iloc[:, -1]\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    for col in discrete_features:\n",
    "        X[col] = labelencoder.fit(X[col]).transform(X[col])\n",
    "    # y = labelencoder.fit(y).fit_transform(y)\n",
    "    y = X.iloc[:, -1]\n",
    "\n",
    "    # for feature in filter(lambda x : x!='NObeyesdad', discrete_features):\n",
    "    #     # 对特征进行排序\n",
    "    #     sorted_values = df[feature].sort_values()\n",
    "        \n",
    "    #     # 计算中位数\n",
    "    #     median_value = sorted_values.median()\n",
    "    #     median_dict[feature] = median_value\n",
    "    #     # 分类：高于或低于中位数\n",
    "    #     df[feature] = df[feature].apply(lambda x: 1 if x > median_value else 0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # print(median_dict)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data('./data/ObesityDataSet_raw_and_data_sinthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Gender  Height  Weight  CALC  FAVC  FCVC  NCP  SCC  SMOKE  CH2O  \\\n",
      "544     0       0       1       0     3     1     0    1    0      0     0   \n",
      "1987    1       0       0       1     2     1     1    0    0      0     1   \n",
      "420     0       1       1       0     2     1     1    1    1      0     0   \n",
      "527     0       0       0       0     2     1     1    0    0      0     0   \n",
      "196     0       1       1       0     2     0     0    0    0      0     0   \n",
      "...   ...     ...     ...     ...   ...   ...   ...  ...  ...    ...   ...   \n",
      "447     0       1       1       1     2     1     0    1    0      0     0   \n",
      "1793    1       1       0       1     3     1     1    0    0      0     0   \n",
      "73      0       1       1       0     2     0     0    0    0      0     1   \n",
      "1711    1       1       1       1     2     1     0    0    0      0     1   \n",
      "1103    0       1       0       0     3     0     1    0    0      0     0   \n",
      "\n",
      "      family_history_with_overweight  FAF  TUE  CAEC  MTRANS  NObeyesdad  \n",
      "544                                1    1    1     1       3           0  \n",
      "1987                               1    0    0     2       3           4  \n",
      "420                                1    1    0     2       0           0  \n",
      "527                                0    0    0     1       3           0  \n",
      "196                                1    0    1     2       1           1  \n",
      "...                              ...  ...  ...   ...     ...         ...  \n",
      "447                                1    1    1     2       3           5  \n",
      "1793                               1    1    0     2       3           3  \n",
      "73                                 1    1    1     2       1           1  \n",
      "1711                               1    0    1     2       0           3  \n",
      "1103                               1    0    0     2       3           6  \n",
      "\n",
      "[423 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ObesityDataSet_raw_and_data_sinthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                           22.740275\n",
       "Gender                                             Male\n",
       "Height                                         1.717288\n",
       "Weight                                        75.948164\n",
       "CALC                                          Sometimes\n",
       "FAVC                                                yes\n",
       "FCVC                                                2.0\n",
       "NCP                                                 3.0\n",
       "SCC                                                  no\n",
       "SMOKE                                                no\n",
       "CH2O                                                2.0\n",
       "family_history_with_overweight                      yes\n",
       "FAF                                                 0.0\n",
       "TUE                                                 2.0\n",
       "CAEC                                          Sometimes\n",
       "MTRANS                            Public_Transportation\n",
       "NObeyesdad                           Overweight_Level_I\n",
       "Name: 817, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "X, y = df.iloc[:, :], df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                             20.0\n",
      "Gender                                          Male\n",
      "Height                                          1.83\n",
      "Weight                                          85.0\n",
      "CALC                                       Sometimes\n",
      "FAVC                                              no\n",
      "FCVC                                             3.0\n",
      "NCP                                              3.0\n",
      "SCC                                              yes\n",
      "SMOKE                                             no\n",
      "CH2O                                             3.0\n",
      "family_history_with_overweight                   yes\n",
      "FAF                                              3.0\n",
      "TUE                                              0.0\n",
      "CAEC                                       Sometimes\n",
      "MTRANS                                    Automobile\n",
      "NObeyesdad                        Overweight_Level_I\n",
      "Name: 192, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, row in X_test.iterrows():\n",
    "    if index == 192:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "continue_list = [818, 192]\n",
    "if 818 in continue_list:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
