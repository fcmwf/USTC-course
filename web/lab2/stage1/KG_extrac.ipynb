{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取待抽取Freebase图谱实体ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreebaseID = set()\n",
    "with open(\"douban2fb.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        FreebaseID.add(line.split(\"\\t\")[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化pd结构存储三元结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_triplet = pd.DataFrame()\n",
    "pd_triplet['head'] = None\n",
    "pd_triplet['relation'] = None\n",
    "pd_triplet['tail'] = None\n",
    "pd_triplet.to_csv(\"freebase_douban.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匹配实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_FreebaseID = FreebaseID.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_entity(ID)-> bool :\n",
    "    if ID in ori_FreebaseID:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到与豆瓣ID映射实体相同的triplet(一跳)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "with gzip.open(\"freebase_douban.gz\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        triplet = line.decode().split('\\t')[:3]\n",
    "        if match_entity(triplet[0].strip(\"<>\").split('/')[-1]):\n",
    "            new_row = {\"head\":triplet[0].strip(\"<>\"),\"relation\":triplet[1].strip(\"<>\"),\"tail\":triplet[2].strip(\"<>\")}\n",
    "            pd_triplet = pd_triplet.append(new_row,ignore_index=True)\n",
    "            if(triplet[2].startswith(\"<http://rdf.freebase.com/ns/\")):\n",
    "                FreebaseID.add(triplet[2].strip(\"<>\").split('/')[-1])\n",
    "        j += 1\n",
    "        if(j % 1000000==0):\n",
    "          pd_triplet.to_csv('freebase_douban.csv', mode='a', index=False, header = False)\n",
    "          temp = pd.read_csv('freebase_douban.csv')\n",
    "          print(j)\n",
    "          print(\"Length of pd_triplet:\", len(temp))\n",
    "          pd_triplet = pd_triplet[0:0]\n",
    "          \n",
    "pd_triplet.to_csv('freebase_douban.csv', mode='a', index=False, header = False)\n",
    "temp = pd.read_csv('freebase_douban.csv')\n",
    "print(j)\n",
    "print(\"Length of pd_triplet:\", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"first_entity\", 'w') as file:\n",
    "    for element in FreebaseID:\n",
    "        file.write(str(element) + '\\n')\n",
    "FreebaseID.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreebaseID.clear()\n",
    "pd_triplet = pd.read_csv('first_freebase_douban.csv')\n",
    "with open(\"first_entity\", 'r') as file:\n",
    "    FreebaseID = {line.strip() for line in file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选实体,得到第二跳的实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计不同实体出现次数\n",
    "entity_num = {key: 0 for key in FreebaseID}\n",
    "relation_num = dict()\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    head = row['head']\n",
    "    relation = row['relation']\n",
    "    tail = row['tail']\n",
    "    if head.split('/')[-1] in entity_num:\n",
    "        entity_num[head.split('/')[-1]] += 1\n",
    "    if tail.split('/')[-1] in entity_num:\n",
    "        entity_num[tail.split('/')[-1]] += 1\n",
    "    if relation in relation_num:\n",
    "        relation_num[relation] += 1\n",
    "    else:\n",
    "        relation_num[relation] = 0\n",
    "to_be_delete = []\n",
    "# 保留了至少出现在 20 个三元组中的实体，同时只保留出现超过 50 次的关系\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    if relation_num[row['relation']] < 50 :\n",
    "        to_be_delete.append(index)\n",
    "pd_triplet = pd_triplet.drop(to_be_delete)\n",
    "# 得到第二跳的实体\n",
    "FreebaseID.clear()\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    if row['head'].startswith(\"http://rdf.freebase.com/ns/\") and entity_num[row['head'].split('/')[-1]] >= 20:\n",
    "        FreebaseID.add(row['head'].split('/')[-1])\n",
    "    if row['tail'].startswith(\"http://rdf.freebase.com/ns/\") and entity_num[row['tail'].split('/')[-1]] >= 20:\n",
    "        FreebaseID.add(row['tail'].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"first_selected_entity\", 'w') as file:\n",
    "    for element in FreebaseID:\n",
    "        file.write(str(element) + '\\n')\n",
    "FreebaseID.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到与豆瓣ID映射实体相同的triplet(二跳)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_triplet = pd.DataFrame()\n",
    "pd_triplet['head'] = None\n",
    "pd_triplet['relation'] = None\n",
    "pd_triplet['tail'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_triplet = pd.DataFrame()\n",
    "pd_triplet['head'] = None\n",
    "pd_triplet['relation'] = None\n",
    "pd_triplet['tail'] = None\n",
    "pd_triplet.to_csv(\"second_freebase_douban.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"first_selected_entity\", 'r') as file:\n",
    "    second_ori_FreebaseID = {line.strip() for line in file}\n",
    "second_FreebaseID = second_ori_FreebaseID.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "j = 0\n",
    "entity_num = {key: 0 for key in second_FreebaseID}\n",
    "with gzip.open(\"freebase_douban.gz\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        triplet = line.decode().split('\\t')[:3]\n",
    "        if triplet[0].strip(\"<>\").split('/')[-1]  in second_ori_FreebaseID:\n",
    "            new_row = {\"head\":triplet[0].strip(\"<>\"),\"relation\":triplet[1].strip(\"<>\"),\"tail\":triplet[2].strip(\"<>\")}\n",
    "            pd_triplet = pd_triplet._append(new_row,ignore_index=True)\n",
    "            if(triplet[2].startswith(\"<http://rdf.freebase.com/ns/\")):\n",
    "                second_FreebaseID.add(triplet[2].strip(\"<>\").split('/')[-1])\n",
    "            entity_num[triplet[0].strip(\"<>\").split('/')[-1]] += 1\n",
    "            if entity_num[triplet[0].strip(\"<>\").split('/')[-1]] >= 20000:  #有的实体出现太多次了！\n",
    "              second_ori_FreebaseID.remove(triplet[0].strip(\"<>\").split('/')[-1])\n",
    "              print(\"i have removed:\",triplet[0].strip(\"<>\").split('/')[-1])\n",
    "        j += 1\n",
    "        if(j % 1000000==0):\n",
    "          temp = pd.read_csv('second_freebase_douban.csv')\n",
    "          print(j)\n",
    "          print(\"Length of pd_triplet:\", len(temp))\n",
    "        if( len(pd_triplet) > 10000):\n",
    "          pd_triplet.to_csv('second_freebase_douban.csv', mode='a', index=False, header = False)\n",
    "          pd_triplet = pd_triplet[0:0]\n",
    "          \n",
    "pd_triplet.to_csv('second_freebase_douban.csv', mode='a', index=False, header = False)\n",
    "temp = pd.read_csv('second_freebase_douban.csv')\n",
    "print(j)\n",
    "print(\"Length of pd_triplet:\", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"second_entity\", 'w') as file:\n",
    "    for element in second_FreebaseID:\n",
    "        file.write(str(element) + '\\n')\n",
    "second_FreebaseID.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选第二跳实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_triplet = pd.read_csv('first_freebase_douban.csv')\n",
    "with open(\"second_entity\", 'r') as file:\n",
    "    second_FreebaseID = {line.strip() for line in file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_triplet = pd.read_csv('second_freebase_douban.csv')\n",
    "#统计不同实体出现次数\n",
    "second_entity_num = {key: 0 for key in second_FreebaseID}\n",
    "second_relation_num = dict()\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    head = row['head']\n",
    "    relation = row['relation']\n",
    "    tail = row['tail']\n",
    "    if head.split('/')[-1] in second_entity_num:\n",
    "        second_entity_num[head.split('/')[-1]] += 1\n",
    "    if tail.split('/')[-1] in second_entity_num:\n",
    "        second_entity_num[tail.split('/')[-1]] += 1\n",
    "    if relation in second_relation_num:\n",
    "        second_relation_num[relation] += 1\n",
    "    else:\n",
    "        second_relation_num[relation] = 0\n",
    "to_be_delete = []\n",
    "# 保留了至少出现在 20 个三元组中的实体，同时只保留出现超过 50 次的关系\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    flag = (row['head'].split('/')[-1] in second_entity_num and 19500 >= second_entity_num[row['head'].split('/')[-1]] >= 18) and (row['tail'].split('/')[-1] in second_entity_num and 19500 >= second_entity_num[row['tail'].split('/')[-1]] >= 18)\n",
    "    if second_relation_num[row['relation']] < 50 or not flag :\n",
    "        to_be_delete.append(index)\n",
    "pd_triplet = pd_triplet.drop(to_be_delete)\n",
    "# 得到第二跳的实体\n",
    "second_FreebaseID.clear()\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    if row['head'].startswith(\"http://rdf.freebase.com/ns/\") :\n",
    "        second_FreebaseID.add(row['head'].split('/')[-1])\n",
    "    if row['tail'].startswith(\"http://rdf.freebase.com/ns/\") :\n",
    "        second_FreebaseID.add(row['tail'].split('/')[-1])\n",
    "\n",
    "# 得到第二跳剩余的关系：\n",
    "second_relation_num.clear()\n",
    "for index, row in pd_triplet.iterrows():\n",
    "    head = row['head']\n",
    "    relation = row['relation']\n",
    "    tail = row['tail']\n",
    "    if relation in second_relation_num:\n",
    "        second_relation_num[relation] += 1\n",
    "    else:\n",
    "        second_relation_num[relation] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in FreebaseID:\n",
    "    if element not in second_FreebaseID:\n",
    "        print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_FreebaseID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42701"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movie_relation\", 'w') as file:\n",
    "    for key, value in second_relation_num.items():\n",
    "        # if value >= 50:\n",
    "        file.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"second_selected_entity\", 'w') as file:\n",
    "    for element in second_FreebaseID:\n",
    "        file.write(str(element) + '\\n')\n",
    "second_FreebaseID.clear()\n",
    "pd_triplet.to_csv(\"second_selected_freebase_douban.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
